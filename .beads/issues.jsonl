{"id":"cg-55e","title":"status command makes unnecessary API calls for legacy manager check","description":"The CLI status command calls _show_legacy_manager_notice() which calls env.get_manager_status(). This method fetches latest_version from the live registry API (~1.2s), but the status command only uses the is_legacy field (a local symlink check). Fix: either inline the symlink check in _show_legacy_manager_notice(), or add a lightweight is_legacy_manager() method that skips the API call.","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-29T18:09:21.456171199-05:00","created_by":"ubuntu","updated_at":"2025-12-30T03:05:57.904680601-05:00"}
{"id":"cg-pnm","title":"Design agent-based QA testing system","description":"## Problem Statement\n\nComfyGit has complex multi-step user flows that unit/integration tests don't fully capture:\n- Workspaces with multiple environments\n- Collaborator sync via push/pull\n- Import/export workflows\n- Workflow resolution with node conflicts\n- Model resolution across sources\n\nManual testing doesn't scale. Users report bugs involving complex command sequences that are hard to replicate in traditional pytest fixtures.\n\n## Proposed Solution\n\nAgent-based QA testing in reproducible containers:\n1. **Nix/Docker images** with deterministic starting state\n2. **Claude Haiku/Sonnet agents** executing test scenarios via CLI\n3. **Structured reports** documenting findings and UX issues\n4. **Parallel execution** (5+ agents) for cost efficiency\n5. **Future: UI testing** inside ComfyUI container\n\n## Key Design Decisions\n\n### Agents for Discovery, Pytest for Regression\n- Agents explore and find bugs (non-deterministic)\n- Once found, convert to deterministic integration tests\n- Don't use agents as CI gates (too slow/expensive)\n\n### Scenario-Based Execution\nDefine scenarios in YAML that agents execute:\n```yaml\nname: Collaborator sync with conflicting node versions\nsteps:\n  - setup: create_workspace --name test-collab\n  - action: node add comfyui-manager==1.0.0\n  - action: git push origin main\n  - setup: simulate_collaborator_push\n  - action: git pull\n  - assert: should_detect_conflict\n```\n\n### Cost Model\n- Haiku: ~$0.25/M input, ~$1.25/M output\n- Target: ~$1-5 per comprehensive test run\n- Run weekly or on-demand, not every commit\n\n## Proposed Directory Structure\n\n```\nqa/\n├── Dockerfile              # Base image: comfygit, claude, uv, git\n├── nix/\n│   └── qa-env.nix          # Optional stricter reproducibility\n├── scenarios/\n│   ├── workflow_sync.yaml\n│   ├── node_conflict.yaml\n│   └── model_resolution.yaml\n├── agent_instructions/\n│   ├── base_system.md      # Core agent behavior\n│   ├── scenario_runner.md  # How to execute scenarios\n│   └── report_format.md    # Required output structure\n├── reports/\n│   └── {timestamp}_{scenario}_{agent_id}.md\n├── scripts/\n│   ├── run_qa.py           # Orchestrate agent containers\n│   ├── parse_reports.py    # Aggregate findings\n│   └── generate_tests.py   # Convert findings to pytest\n└── README.md\n```\n\n## Existing Infrastructure to Build On\n\n- `dev/docker-compose.yml` - Existing Docker setup with GPU support\n- `dev/scripts/cross-platform-test.py` - Parallel test orchestration pattern\n- `packages/core/tests/conftest.py` - 500+ lines of fixtures\n- `packages/core/tests/helpers/` - Fluent test builders (WorkflowBuilder, etc.)\n\n## Implementation Phases\n\n### Phase 1: Proof of Concept\n- [ ] Single scenario, single agent, manual triggering\n- [ ] Basic Dockerfile extending existing dev setup\n- [ ] Simple report format (markdown)\n- [ ] Validate: does agent find real bugs?\n\n### Phase 2: Structure\n- [ ] Scenario YAML DSL design\n- [ ] Structured report format (JSON + markdown)\n- [ ] Agent instruction engineering\n- [ ] Orchestration script\n\n### Phase 3: Scale\n- [ ] Parallel agent execution\n- [ ] Report aggregation and analysis\n- [ ] Integration test generation from findings\n- [ ] Weekly automated runs\n\n## Open Questions\n\n1. Should scenarios be purely declarative or allow agent exploration?\n2. How much ComfyUI setup is needed in containers?\n3. Should we use Nix from the start or defer?\n4. How to handle agent-found bugs that can't be reproduced?\n\n## References\n\n- Discussion context: Agent-based QA testing strategy\n- Existing test stats: ~17K lines integration tests, 90+ tests in core\n- Cross-platform support: Linux, Windows, macOS via SSH","status":"in_progress","priority":2,"issue_type":"epic","created_at":"2025-12-30T02:39:42.649127688-05:00","created_by":"ubuntu","updated_at":"2025-12-30T03:05:57.904312406-05:00","comments":[{"id":1,"issue_id":"cg-pnm","author":"ubuntu","text":"Restructured as epic with 3 phase tasks. Phase 1 PoC complete - validates the approach works. Branch: feature/agent-qa-system","created_at":"2025-12-30T08:02:19Z"},{"id":2,"issue_id":"cg-pnm","author":"ubuntu","text":"Session: Docker-in-Docker + Auth Sharing Setup\n\nAdded portable docker-compose.yml with environment variable configuration:\n- CLAUDE_AUTH_PATH: Path to Claude credentials\n- COMFYGIT_PATH: Path to comfygit repo (HOST path for DinD)\n- Works on both direct host and Docker-in-Docker (ACFS) setups\n\nClaude Auth Sharing for DinD:\n- Added claude-auth named volume to ACFS docker-compose.yml\n- Added entrypoint.sh logic to symlink .credentials.json to shared volume\n- QA container copies credentials on startup to writable /root/.claude/\n- OAuth tokens refresh in ACFS, child containers inherit automatically\n\nNew files:\n- qa/docker-compose.yml - Portable container config\n- qa/.env.example - Configuration template\n- qa/CLAUDE.md - Setup and usage instructions for agents\n\nUpdated:\n- /data/ai-tools/acfs-setup/docker-compose.yml - claude-auth volume\n- /data/ai-tools/acfs-setup/entrypoint.sh - Auth symlink setup\n- qa/Dockerfile - Removed BuildKit cache mounts for compatibility\n- qa/.gitignore - Added .env and placeholder entries\n\nVolume created: acfs-setup_claude-auth (seeded with current credentials)\n\nTested: Claude CLI works in QA container with inherited OAuth auth.","created_at":"2025-12-30T21:27:35Z"}]}
{"id":"cg-pnm.1","title":"Phase 1: PoC - single agent, manual triggering","description":"Single scenario, single agent, manual triggering. Basic Dockerfile, simple report format. Validate that agent can find real bugs.\n\nDeliverables:\n- qa/Dockerfile with ComfyGit + Claude CLI\n- qa/agent_instructions/ with base system prompt\n- qa/scenarios/ with initial test scenarios\n- qa/scripts/run_scenario.py orchestration script\n- Dry-run and native modes for testing without API","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T03:01:32.365620116-05:00","created_by":"ubuntu","updated_at":"2025-12-30T03:05:57.903921113-05:00","closed_at":"2025-12-30T03:02:11.174705316-05:00","close_reason":"Implemented in f63c435 on feature/agent-qa-system branch","dependencies":[{"issue_id":"cg-pnm.1","depends_on_id":"cg-pnm","type":"parent-child","created_at":"2025-12-30T03:01:32.367791857-05:00","created_by":"daemon"}]}
{"id":"cg-pnm.2","title":"Phase 2: Structured scenarios and reports","description":"Refine the scenario YAML DSL, add structured JSON+markdown report format, improve agent instruction engineering, enhance orchestration script.\n\nDeliverables:\n- Scenario YAML DSL with validation\n- Structured report format (JSON + markdown)\n- Refined agent instructions based on Phase 1 learnings\n- Better error handling in orchestration","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T03:01:43.15770262-05:00","created_by":"ubuntu","updated_at":"2025-12-30T03:22:00.617884367-05:00","closed_at":"2025-12-30T03:22:00.617884367-05:00","close_reason":"Phase 2 complete: schema validation, structured reports, refined instructions","dependencies":[{"issue_id":"cg-pnm.2","depends_on_id":"cg-pnm","type":"parent-child","created_at":"2025-12-30T03:01:43.159787925-05:00","created_by":"daemon"},{"issue_id":"cg-pnm.2","depends_on_id":"cg-pnm.1","type":"blocks","created_at":"2025-12-30T03:02:02.184187529-05:00","created_by":"daemon"}]}
{"id":"cg-pnm.3","title":"Phase 3: Scale - parallel execution and automation","description":"Scale to multiple parallel agents, aggregate reports, generate regression tests from findings, set up weekly automated runs.\n\nDeliverables:\n- Parallel agent execution (5+ agents)\n- Report aggregation and analysis script\n- Integration test generation from agent findings\n- Weekly automated run configuration (cron/CI)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-30T03:01:53.300004094-05:00","created_by":"ubuntu","updated_at":"2025-12-30T03:05:57.903110471-05:00","dependencies":[{"issue_id":"cg-pnm.3","depends_on_id":"cg-pnm","type":"parent-child","created_at":"2025-12-30T03:01:53.30186273-05:00","created_by":"daemon"},{"issue_id":"cg-pnm.3","depends_on_id":"cg-pnm.2","type":"blocks","created_at":"2025-12-30T03:02:02.191668498-05:00","created_by":"daemon"}]}
